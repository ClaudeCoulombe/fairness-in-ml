{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# HIDE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# HIDE\n",
    "def load_ICU_data(path):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', \n",
    "                    'martial_status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                    'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
    "    input_data = (pd.read_csv(path, names=column_names, \n",
    "                              na_values=\"?\", sep=r'\\s*,\\s*', engine='python')\n",
    "                  .loc[lambda df: df['race'].isin(['White', 'Black'])])\n",
    "\n",
    "    # sensitive attributes; we identify 'race' and 'sex' as sensitive attributes\n",
    "    sensitive_attribs = ['race', 'sex']\n",
    "    Z = (input_data.loc[:, sensitive_attribs]\n",
    "         .assign(race=lambda df: (df['race'] == 'White').astype(int),\n",
    "                 sex=lambda df: (df['sex'] == 'Male').astype(int)))\n",
    "\n",
    "    # targets; 1 when someone makes over 50k , otherwise 0\n",
    "    y = (input_data['target'] == '>50K').astype(int)\n",
    "\n",
    "    # features; note that the 'target' and sentive attribute columns are dropped\n",
    "    X = (input_data\n",
    "         .drop(columns=['target', 'race', 'sex'])\n",
    "         .fillna('Unknown')\n",
    "         .pipe(pd.get_dummies, drop_first=True))\n",
    "    \n",
    "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
    "    print(f\"targets y: {y.shape} samples\")\n",
    "    print(f\"sensitives Z: {Z.shape[0]} samples, {Z.shape[1]} attributes\")\n",
    "    return X, y, Z\n",
    "\n",
    "\n",
    "def p_rule(y_pred, z_values, threshold=0.5):\n",
    "    y_z_1 = y_pred[z_values == 1] > threshold if threshold else y_pred[z_values == 1]\n",
    "    y_z_0 = y_pred[z_values == 0] > threshold if threshold else y_pred[z_values == 0]\n",
    "    odds = y_z_1.mean() / y_z_0.mean()\n",
    "    return np.min([odds, 1/odds]) * 100\n",
    "\n",
    "\n",
    "def plot_dists(y_true, Z_true, y_pred, Z_pred=None, epoch=None):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "    subplot_df = (\n",
    "        Z_true\n",
    "        .assign(race=lambda x: x['race'].map({1: 'white', 0: 'black'}))\n",
    "        .assign(sex=lambda x: x['sex'].map({1: 'male', 0: 'female'}))\n",
    "        .assign(y_pred=y_pred)\n",
    "    )\n",
    "    _subplot(subplot_df, 'race', ax=axes[0])\n",
    "    _subplot(subplot_df, 'sex', ax=axes[1])\n",
    "    _performance_text(fig, y_true, Z_true, y_pred, Z_pred, epoch)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "\n",
    "def _subplot(subplot_df, col, ax):\n",
    "    for label, df in subplot_df.groupby(col):\n",
    "        sns.kdeplot(df['y_pred'], ax=ax, label=label, shade=True)\n",
    "    ax.set_title(f'Sensitive attribute: {col}')\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,7)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylabel('Prediction distribution')\n",
    "    ax.set_xlabel(r'$P({{income>50K}}|z_{{{}}})$'.format(col))\n",
    "\n",
    "def _performance_text(fig, y_test, Z_test, y_pred, Z_pred=None,\n",
    "                     epoch=None):   \n",
    "\n",
    "    if epoch is not None:\n",
    "        fig.text(1.0, 0.9, f\"Training epoch #{epoch}\", fontsize='16')\n",
    "\n",
    "    clf_roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    clf_accuracy = metrics.accuracy_score(y_test, y_pred > 0.5) * 100\n",
    "    p_rules = {'race': p_rule(y_pred, Z_test['race']),\n",
    "               'sex': p_rule(y_pred, Z_test['sex']),}\n",
    "    fig.text(1.0, 0.65, '\\n'.join([\"Classifier performance:\",\n",
    "                                   f\"- ROC AUC: {clf_roc_auc:.2f}\",\n",
    "                                   f\"- Accuracy: {clf_accuracy:.1f}\"]),\n",
    "             fontsize='16')\n",
    "    fig.text(1.0, 0.4, '\\n'.join([\"Satisfied p%-rules:\"] +\n",
    "                                 [f\"- {attr}: {p_rules[attr]:.0f}%-rule\" \n",
    "                                  for attr in p_rules.keys()]), \n",
    "             fontsize='16')\n",
    "    if Z_pred is not None:\n",
    "        adv_roc_auc = metrics.roc_auc_score(Z_test, Z_pred)\n",
    "        fig.text(1.0, 0.20, '\\n'.join([\"Adversarial performance:\",\n",
    "                               f\"- ROC AUC: {adv_roc_auc:.2f}\"]),\n",
    "                                 fontsize='16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load ICU data set\n",
    "X, y, Z = load_ICU_data('data/adult.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split into train/test set\n",
    "X_train, X_test, y_train, y_test, Z_train, Z_test = train_test_split(X, y, Z, test_size=0.5, \n",
    "                                                                     stratify=y, random_state=7)\n",
    "\n",
    "# standardize the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
    "X_train = X_train.pipe(scale_df, scaler) \n",
    "X_test = X_test.pipe(scale_df, scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class IcuDataset(TensorDataset):\n",
    "\n",
    "    def __init__(self, X, y, Z):\n",
    "        X = torch.from_numpy(X.as_matrix()).float()\n",
    "        y = torch.from_numpy(y.to_frame('y').as_matrix()).float()\n",
    "        Z = torch.from_numpy(Z.as_matrix()).float()\n",
    "        super(IcuDataset, self).__init__(X, y, Z)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Z = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = IcuDataset(X_train, y_train, Z_train)\n",
    "test_data = IcuDataset(X_test, y_test, Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=24, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, n_hidden=32, p_dropout=0.2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            self.dropout,\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.out(x))\n",
    "    \n",
    "\n",
    "def pretrain_classifier(clf, data_loader, optimizer, criterion):\n",
    "    for x, y, _ in data_loader:\n",
    "        clf.zero_grad()\n",
    "        p_y = clf(x)\n",
    "        loss = criterion(p_y, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf = Classifier(X_train.shape[1])\n",
    "clf_criterion = nn.BCELoss()\n",
    "clf_optimizer = optim.Adam(clf.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_CLF_EPOCHS = 1\n",
    "\n",
    "for epoch in range(N_CLF_EPOCHS):\n",
    "    clf = pretrain_classifier(clf, train_loader, clf_optimizer, clf_criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pre_clf_test = clf(test_data.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pre_clf = pd.Series(pre_clf_test.data.numpy().ravel(),\n",
    "                      index=y_test.index)\n",
    "_ = plot_dists(y_test, Z_test, y_pre_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adverserial pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Adverserial(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_sensitive, n_hidden=32):\n",
    "        super(Adverserial, self).__init__()\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(1, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_sensitive),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.out(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pretrain_adverserial(adv, clf, data_loader, optimizer, criterion):\n",
    "    for x, _, z in data_loader:\n",
    "        p_y = clf(x).detach()\n",
    "        adv.zero_grad()\n",
    "        p_z = adv(p_y)\n",
    "        loss = criterion(p_z, z)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adv = Adverserial(Z_train.shape[1])\n",
    "adv_criterion = nn.BCELoss()\n",
    "adv_optimizer = optim.Adam(adv.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_ADV_EPOCHS = 1\n",
    "\n",
    "for epoch in range(N_ADV_EPOCHS):\n",
    "    pretrain_adverserial(adv, clf, train_loader, adv_optimizer, adv_criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pre_adv_test = adv(pre_clf_test)\n",
    "    \n",
    "y_pre_adv = pd.DataFrame(pre_adv_test.numpy(), columns=Z.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plot_dists(y_test, Z_test, y_pre_clf, y_pre_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_adv_criterion = nn.BCELoss(reduce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lambdas = 0.1 * torch.Tensor([130, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(clf, adv, data_loader, clf_criterion, adv_criterion,\n",
    "          clf_adv_criterion, clf_optimizer, adv_optimizer):\n",
    "    for x, y, z in data_loader:\n",
    "        \n",
    "        p_y = clf(x)\n",
    "\n",
    "        # Train adversarial\n",
    "        adv.zero_grad()\n",
    "        p_adv = adv(p_y)\n",
    "        loss_adv = adv_criterion(p_adv, z)\n",
    "        loss_adv.backward(retain_graph=True)\n",
    "        adv_optimizer.step()\n",
    "\n",
    "        # Train classifier\n",
    "        clf.zero_grad()\n",
    "        clf_loss = clf_criterion(p_y, y) - (clf_adv_criterion(p_adv, z) * lambdas).sum()\n",
    "        clf_loss.backward()\n",
    "        clf_optimizer.step()\n",
    "    \n",
    "    return clf, adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    \n",
    "    clf, adv = train(clf, adv, train_loader, clf_criterion, adv_criterion,\n",
    "                     clf_adv_criterion, clf_optimizer, adv_optimizer)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        clf_pred = clf(test_data.X)\n",
    "        adv_pred = adv(clf_pred)\n",
    "    \n",
    "    y_post_clf = pd.Series(clf_pred.numpy().ravel(), index=y_test.index)\n",
    "    Z_post_adv = pd.DataFrame(adv_pred.numpy(), columns=Z_test.columns)\n",
    "\n",
    "    plot_dists(y_test, Z_test, y_post_clf, Z_post_adv, epoch)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:fairness-in-ml]",
   "language": "python",
   "name": "conda-env-fairness-in-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
